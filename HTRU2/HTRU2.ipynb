{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1DYU9uGaIN50-snUbAi6Z8DlPWpKrBxcA?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\alexa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\alexa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\alexa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ucimlrepo) (2024.8.30)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\alexa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alexa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alexa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alexa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alexa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\alexa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Install the ucimlrepo package\n",
    "%pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 372, 'name': 'HTRU2', 'repository_url': 'https://archive.ics.uci.edu/dataset/372/htru2', 'data_url': 'https://archive.ics.uci.edu/static/public/372/data.csv', 'abstract': 'Pulsar candidates collected during the HTRU survey. Pulsars are a type of star, of considerable scientific interest. Candidates must be classified in to pulsar and non-pulsar classes to aid discovery.', 'area': 'Physics and Chemistry', 'tasks': ['Classification', 'Clustering'], 'characteristics': ['Multivariate'], 'num_instances': 17898, 'num_features': 8, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2015, 'last_updated': 'Wed Apr 03 2024', 'dataset_doi': '10.24432/C5DK6R', 'creators': ['Robert Lyon'], 'intro_paper': {'ID': 460, 'type': 'NATIVE', 'title': 'Fifty years of pulsar candidate selection: from simple filters to a new principled real-time classification approach', 'authors': 'R. Lyon, B. Stappers, S. Cooper, J. M. Brooke, Joshua D. Knowles', 'venue': 'Monthly notices of the Royal Astronomical Society', 'year': 2016, 'journal': None, 'DOI': '10.1093/mnras/stw656', 'URL': 'https://www.semanticscholar.org/paper/e81657338e48b233c8c6019832e6670fa552adb4', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': \"HTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey (South) [1]. \\r\\n\\r\\nPulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter (see [2] for more uses). \\r\\n\\r\\nAs pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsars\\r\\nrotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes.\\r\\n\\r\\nEach pulsar produces a slightly different emission pattern, which varies slightly with each rotation (see [2] for an introduction to pulsar astrophysics to find out why). Thus a  potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find.\\r\\n\\r\\nMachine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted,\\r\\n(see [4,5,6,7,8,9]) which treat the candidate data sets  as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class. At present multi-class labels are unavailable, given the costs associated with data annotation.\\r\\n\\r\\nThe data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators. \\r\\n\\r\\nThe data is presented in two formats: CSV and ARFF (used by the WEKA data mining tool). Candidates are stored in both files in separate rows. Each row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive).\\r\\n\\r\\nPlease note that the data contains no positional information or other astronomical details. It is simply feature data extracted from candidate files using the PulsarFeatureLab tool (see [10]).\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency (see [3] for more details). The remaining four variables are similarly obtained from the DM-SNR curve (again see [3] for more details). These are summarised below:\\r\\n\\r\\n1. Mean of the integrated profile.\\r\\n2. Standard deviation of the integrated profile.\\r\\n3. Excess kurtosis of the integrated profile.\\r\\n4. Skewness of the integrated profile.\\r\\n5. Mean of the DM-SNR curve.\\r\\n6. Standard deviation of the DM-SNR curve.\\r\\n7. Excess kurtosis of the DM-SNR curve.\\r\\n8. Skewness of the DM-SNR curve.\\r\\n9. Class\\r\\n\\r\\nHTRU 2 Summary\\r\\n17,898 total examples.\\r\\n1,639 positive examples.\\r\\n16,259 negative examples.', 'citation': 'If you use the dataset in your work, please cite us using the following paper:\\n\\nR. J. Lyon, B. W. Stappers, S. Cooper, J. M. Brooke, J. D. Knowles, Fifty Years of Pulsar Candidate Selection: From simple filters to a new principled real-time classification approach, Monthly Notices of the Royal Astronomical Society 459 (1), 1104-1123, DOI: 10.1093/mnras/stw656\\n\\nIf possible, please also cite the DOI of the data set directly:\\n\\nR. J. Lyon, HTRU2, DOI: 10.6084/m9.figshare.3080389.v1.\\n\\nAcknowledgements\\n\\nThis data was obtained with the support of grant EP/I028099/1 for the University of Manchester  Centre for Doctoral Training in Computer Science, from the UK Engineering and Physical Sciences Research Council (EPSRC). The raw observational data was collected by the High Time Resolution Universe Collaboration using the Parkes Observatory, funded by the Commonwealth of Australia and managed by the CSIRO.'}}\n",
      "               name     role        type demographic description units  \\\n",
      "0      Profile_mean  Feature  Continuous        None        None  None   \n",
      "1     Profile_stdev  Feature  Continuous        None        None  None   \n",
      "2  Profile_skewness  Feature  Continuous        None        None  None   \n",
      "3  Profile_kurtosis  Feature  Continuous        None        None  None   \n",
      "4           DM_mean  Feature  Continuous        None        None  None   \n",
      "5          DM_stdev  Feature  Continuous        None        None  None   \n",
      "6       DM_skewness  Feature  Continuous        None        None  None   \n",
      "7       DM_kurtosis  Feature  Continuous        None        None  None   \n",
      "8             class   Target      Binary        None        None  None   \n",
      "\n",
      "  missing_values  \n",
      "0             no  \n",
      "1             no  \n",
      "2             no  \n",
      "3             no  \n",
      "4             no  \n",
      "5             no  \n",
      "6             no  \n",
      "7             no  \n",
      "8             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "htru2 = fetch_ucirepo(id=372)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = htru2.data.features\n",
    "y = htru2.data.targets\n",
    "\n",
    "# metadata\n",
    "print(htru2.metadata)\n",
    "\n",
    "# variable information\n",
    "print(htru2.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando bibliotecas de treino, acurácia, precisão e recall\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "#função para calcular métricas médias apos as cinco execuções\n",
    "def calculaMetrica(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acuracia = accuracy_score(y_test, y_pred)\n",
    "    precisao = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    return acuracia, precisao, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo KNN para armazenar exibir os resultados\n",
    "modelos = {\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Variáveis para armazenar os resultados\n",
    "resultados = {nomeModelo: {\"acurácia\": [], \"precisão\": [], \"recall\": []} for nomeModelo in modelos.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': {'acurácia': np.float64(0.9720121028744326),\n",
       "  'precisão': np.float64(0.904387793325135),\n",
       "  'recall': np.float64(0.776041056865248)}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#utilização do 'for' para repetir 5 vezes a divisão do esquema de validação holdout e o treinamento para cada modelo\n",
    "for _ in range(5):\n",
    "  # Utilizando 6000 amostras para treino e teste selecionadas aleatóriamente\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), train_size=6000, random_state=None)\n",
    "\n",
    "  #calculando as métricas para cada modelo\n",
    "  for nomeModelo, modelo in modelos.items():\n",
    "    acuracia, precisao, recall = calculaMetrica(modelo, X_train, X_test, y_train, y_test)\n",
    "    resultados[nomeModelo][\"acurácia\"].append(acuracia)\n",
    "    resultados[nomeModelo][\"precisão\"].append(precisao)\n",
    "    resultados[nomeModelo][\"recall\"].append(recall)\n",
    "\n",
    "#calculando as médias das métricas para cada algoritmo\n",
    "averages = {nomeModelo: {metric: np.mean(scores) for metric, scores in metrics.items()} for nomeModelo, metrics in resultados.items()}\n",
    "averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "\n",
    "#carregando arquivos CSV HTRU\n",
    "df = pd.read_csv('HTRU_2.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separação por rótulo\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "#escolhendo cinco valores diferentes/aleatórios para k\n",
    "k_valores = [1, 2, 4, 6, 9]\n",
    "validacaoResultados = {}\n",
    "\n",
    "#dividindo a base de treinamento em duas partes iguais: 50% p treino e 50% p validação\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, train_size=6000, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'Acurácia:': 0.967, 'Tempo de execução': 0.10806512832641602, 'num. prototipos': 3000}, 2: {'Acurácia:': 0.973, 'Tempo de execução': 0.11349248886108398, 'num. prototipos': 3000}, 4: {'Acurácia:': 0.974, 'Tempo de execução': 0.19026660919189453, 'num. prototipos': 3000}, 6: {'Acurácia:': 0.9746666666666667, 'Tempo de execução': 0.10392570495605469, 'num. prototipos': 3000}, 9: {'Acurácia:': 0.9743333333333334, 'Tempo de execução': 0.10547780990600586, 'num. prototipos': 3000}}\n"
     ]
    }
   ],
   "source": [
    "#avaliando cada valor de k\n",
    "for k in k_valores:\n",
    "  tempoInicio = time.time()\n",
    "\n",
    "  #treinando e avaliando com o valor de k. KNN com métrica de distancia euclidiana\n",
    "  knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "  knn.fit(X_train, y_train)\n",
    "\n",
    "  #calculando a acurácia na validação\n",
    "  validacaoAcuracia = knn.score(X_val, y_val)\n",
    "\n",
    "  #Para armazenar resultados e tempo\n",
    "  validacaoResultados[k] = {\n",
    "    \"Acurácia:\": validacaoAcuracia,\n",
    "    \"Tempo de execução\": time.time() - tempoInicio,\n",
    "    #(letra b) num de protótipos usados para cada k\n",
    "    \"num. prototipos\": len(X_train)\n",
    "  }\n",
    "\n",
    "print(validacaoResultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporção das classes:\n",
      "8\n",
      "0    0.908426\n",
      "1    0.091574\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Verificando a proporção das classes\n",
    "contasClasses = y.value_counts(normalize=True)\n",
    "print(\"Proporção das classes:\")\n",
    "print(contasClasses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
